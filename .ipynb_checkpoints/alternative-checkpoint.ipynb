{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-00760cd1c29a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv, DataFrame, concat\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "\n",
    "months = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, \n",
    "          'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10,\n",
    "         'November': 11, 'December': 12}\n",
    "\n",
    "def encode(l):\n",
    "    encoded = []\n",
    "    for m in l:\n",
    "        for key, value in months.items():\n",
    "            if key == m:\n",
    "                encoded.append(value)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%m/%d/%Y')\n",
    "\n",
    "# Data Loading\n",
    "data_set = pd.read_csv('march2020clean.csv', sep =',', date_parser = parse)\n",
    "data_set = data_set.iloc[:data_set['totalSoybeanMealSupply'].last_valid_index(),:] # Truncate dataset to those where every data is available \n",
    "'''\n",
    "'closePrice','openPrice','highPrice','lowPrice','totalSoybeanMealSupply','totalSoybeanMealDemand','soybeanOilSupply','soybeanOilDemand','sunflowerSeedPrice','canolaPrice','peanutsPrice','flaxseedPrice','soybeanOilPrice','cottonseedOilPrice','sunflowerseedOilPrice','canolaOilPrice','peanutOilPrice','cornOilPrice','soybeanMealPrice','cottonseedmealPrice','sunflowerseedMealPrice','linseedMealPrice'\n",
    "'''\n",
    "target_col = ['closePrice','totalSoybeanMealSupply','totalSoybeanMealDemand', 'Month']\n",
    "data_set['Month'] = encode(data_set['Month'])\n",
    "data_set = data_set.loc[:,target_col]\n",
    "shift = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set\n",
    "values = data_set.values\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(values)\n",
    "scaler2 = MinMaxScaler()\n",
    "scaled2 = scaler2.fit_transform(values[:,0].reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, seq_length, y_col):\n",
    "    X = [] \n",
    "    Y = []\n",
    "    for time in range(len(data)-seq_length):\n",
    "        X += [data[time:time+seq_length]]\n",
    "        Y += [data[time+seq_length][y_col]]\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "data_x, data_y = series_to_supervised(scaled,shift,[0,1,2,3])\n",
    "data_x, data_y = np.asarray(data_x), np.asarray(data_y)\n",
    "train_count = int(len(data_x) * 0.8)\n",
    "\n",
    "train_x, train_y = data_x[:train_count,:,:], data_y[:train_count]\n",
    "test_x, test_y = data_x[train_count:,:,:], data_y[train_count:]\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design network\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 64, return_sequences = False, stateful = False, input_shape = (train_x.shape[1], train_x.shape[2])))\n",
    "regressor.add(Dropout(0.1))\n",
    "regressor.add(Dense(units = 32, activation='relu'))\n",
    "regressor.add(Dropout(0.1))\n",
    "regressor.add(Dense(units = 4))\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "history = regressor.fit(train_x, train_y, epochs = 1000, batch_size = 32, validation_data=(test_x,test_y), verbose=2)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "# print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npredictor = Sequential()\\npredictor.add(LSTM(units = 50, stateful = True, batch_input_shape = (1, None, train_x.shape[2])))\\npredictor.add(Dense(units = 3))\\npredictor.compile(optimizer = 'adam', loss = 'mean_squared_error')\\n\\npredictor.set_weights(regressor.get_weights())\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predictor = Sequential()\n",
    "predictor.add(LSTM(units = 50, stateful = True, batch_input_shape = (1, None, train_x.shape[2])))\n",
    "predictor.add(Dense(units = 3))\n",
    "predictor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "predictor.set_weights(regressor.get_weights())\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2d455bc03222>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mforecast_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_given\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mforecast_distance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_given\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaled' is not defined"
     ]
    }
   ],
   "source": [
    "forecast_distance = 300\n",
    "\n",
    "x_given = scaled[:,:]\n",
    "\n",
    "x_hat = np.zeros((x_given.shape[0] + forecast_distance, x_given.shape[1]))\n",
    "x_hat[:len(x_given),:] = x_given \n",
    "y_hat = np.zeros((x_given.shape[0] + forecast_distance))\n",
    "print(x_hat.shape)\n",
    "for i in range(shift, len(x_given)+forecast_distance):\n",
    "    pred = regressor.predict(x_hat[i-shift:i,:].reshape(1,shift, x_given.shape[1]))\n",
    "    if i >= len(x_given):\n",
    "        x_hat[i,:] = pred \n",
    "    y_hat[i] = pred[0,0]\n",
    "    #predictor.reset_states()\n",
    "\n",
    "y_hat = y_hat[shift:]\n",
    "    \n",
    "yhat2 = regressor.predict(test_x)[:,0]\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = scaler2.inverse_transform(y_hat.reshape(-1,1))\n",
    "# invert scaling for forecast\n",
    "inv_yhat2 = scaler2.inverse_transform(yhat2.reshape(-1,1))\n",
    "# invert scaling for actual\n",
    "inv_y = scaler2.inverse_transform(np.concatenate((train_y[:,0],test_y[:,0]), axis=0).reshape(-1,1))\n",
    "\n",
    "\n",
    "pyplot.figure()\n",
    "pyplot.plot(inv_y, label = 'Actual')\n",
    "pyplot.plot(inv_yhat, label = 'Forecast')\n",
    "pyplot.plot(inv_yhat2, label = 'Forecast2')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
