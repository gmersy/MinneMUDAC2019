{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Jin Hong Kuan and Gabe Mersy\n",
    "import os\n",
    "import warnings  \n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from pandas import read_csv, DataFrame, concat\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras.utils import plot_model\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "# Numerically encoding categorical features\n",
    "\n",
    "months = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, \n",
    "          'June': 6, 'July': 7, 'August': 8, 'September': 9, 'October': 10,\n",
    "         'November': 11, 'December': 12}\n",
    "\n",
    "def encode(l):\n",
    "    encoded = []\n",
    "    for m in l:\n",
    "        for key, value in months.items():\n",
    "            if key == m:\n",
    "                encoded.append(value)\n",
    "    return encoded\n",
    "\n",
    "# Parsing date\n",
    "\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%m/%d/%Y')\n",
    "\n",
    "# Setting intial values revelant to forecast\n",
    "forecast_length = 200\n",
    "\n",
    "# Setting seed for stochastic reproducibility\n",
    "seed = 0\n",
    "tf.set_random_seed(seed)\n",
    "name = 'prices_may2500_' + str(seed)\n",
    "shift = 8\n",
    "# Extending calendar to fit forecast_length\n",
    "add_weeks = math.ceil((forecast_length+shift)/5)\n",
    "\n",
    "# Loading data and conducting preprocessing\n",
    "data_set = pd.read_csv('may2020clean.csv', sep =',', date_parser = parse)\n",
    "data_set = data_set.iloc[:data_set['totalSoybeanMealSupply'].last_valid_index(),:] # Truncate dataset  \n",
    "target_cols = ['closePrice','canolaOilPrice', 'soybeanOilPrice', 'soybeanMealPrice', 'cottonseedmealPrice', 'sunflowerseedMealPrice', 'Month']\n",
    "data_set['Month'] = encode(data_set['Month'])\n",
    "dates = data_set['date'].tolist()\n",
    "data_set = data_set.loc[:,target_cols]\n",
    "\n",
    "for i in range(len(dates)):\n",
    "    dates[i] = parse(dates[i])\n",
    "    \n",
    "last_week = dates[-5:]\n",
    "\n",
    "for i in range(add_weeks):\n",
    "    dates += [x + timedelta(days = 7) for x in last_week]\n",
    "    last_week = dates[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering: mix/max scaling\n",
    "values = data_set.values\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "transformed_dates = scaler2.fit_transform(np.asarray([x.month for x in dates]).reshape(len(dates),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 319, 7)\n",
      "(1, 319, 7)\n"
     ]
    }
   ],
   "source": [
    "# Converting time series to supervised learning format\n",
    "def series_to_supervised(data, seq_length, y_col):\n",
    "    X = [] \n",
    "    Y = []\n",
    "    for time in range(len(data)-seq_length):\n",
    "        X += [data[time:time+seq_length]]\n",
    "        Y += [data[time+seq_length][y_col]]\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "data_x, data_y = scaled[:-shift], scaled[shift:]\n",
    "separation = int(len(data_x)*0.8)\n",
    "train_x, train_y = data_x[:separation], data_y[:separation]\n",
    "test_x, test_y = data_x[separation:], data_y[separation:]\n",
    "train_x = train_x.reshape(1, train_x.shape[0], train_x.shape[1])\n",
    "train_y = train_y.reshape(1, train_y.shape[0], train_y.shape[1])\n",
    "test_x = test_x.reshape(1, test_x.shape[0], test_x.shape[1])\n",
    "test_y = test_y.reshape(1, test_y.shape[0], test_y.shape[1])\n",
    "data_x = data_x.reshape(1, data_x.shape[0], data_x.shape[1])\n",
    "data_y = data_y.reshape(1, data_y.shape[0], data_y.shape[1])\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n"
     ]
    }
   ],
   "source": [
    "# Mean Squared Error function\n",
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    warmup_steps = 50\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n",
    "                                        predictions=y_pred_slice)\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "    return loss_mean\n",
    "\n",
    "# Building LTSM network with stateful = False (non-prediction model)\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, stateful = False, input_shape = (None, train_x.shape[2])))\n",
    "regressor.add(LSTM(units = train_x.shape[2], return_sequences = True, stateful = False))\n",
    "regressor.compile(optimizer = RMSprop(lr=1e-3), loss = loss_mse_warmup)\n",
    "\n",
    "print('Fitting model...')\n",
    "history = regressor.fit(train_x, train_y, epochs = 2500, verbose=0)\n",
    "\n",
    "# Training loss plot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data_set.values\n",
    "values = values.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "print(values[:5,:])\n",
    "scaled = scaler.fit_transform(values)\n",
    "print(scaled[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LTSM network with stateful = True (prediction model)\n",
    "newModel = Sequential()\n",
    "newModel.add(LSTM(units = 50, return_sequences = True, stateful = True, batch_input_shape = (1, None, train_x.shape[2])))\n",
    "newModel.add(LSTM(units = train_x.shape[2], return_sequences = False, stateful = True))\n",
    "\n",
    "newModel.set_weights(regressor.get_weights())\n",
    "\n",
    "forecastFromSelf = np.empty((1, train_x.shape[1] + forecast_length, train_x.shape[2]))\n",
    "forecastData = np.empty((1, train_x.shape[1] + forecast_length, train_x.shape[2]))\n",
    "forecastData[:,:train_x.shape[1], :] = train_x[:,:,:]\n",
    "\n",
    "\n",
    "for i in range(train_x.shape[1]+forecast_length):\n",
    "    input_data = forecastData[:,i:i+1,:]\n",
    "    forecastFromSelf[:,i:i+1,:] = newModel.predict(forecastData[:,i:i+1,:])\n",
    "    forecastFromSelf[:,i,-1] = transformed_dates[i+shift,0] # Replace prediction with what's already known\n",
    "    output_data = forecastFromSelf[:,i:i+1,:]\n",
    "    if i + shift >= train_x.shape[1] and i + shift < forecastData.shape[1]:\n",
    "        forecastData[:,i+shift:i+shift+1,:] = forecastFromSelf[:,i:i+1,:]\n",
    "\n",
    "y_hat = scaler.inverse_transform(forecastFromSelf.reshape((forecastFromSelf.shape[1],forecastFromSelf.shape[2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction plot\n",
    "a = pyplot.figure()\n",
    "a.set_size_inches(10,30)\n",
    "for i in range(y_hat.shape[1]):\n",
    "    ax = a.add_subplot(y_hat.shape[1],1,i+1)\n",
    "    b = data_y\n",
    "    b = b.reshape(b.shape[1], b.shape[2])\n",
    "    b = scaler.inverse_transform(b)\n",
    "    ax.plot(b[:,i])\n",
    "    ax.plot(y_hat[:,i])\n",
    "    ax.title.set_text(target_cols[i])\n",
    "a.savefig(fname='./data/{}.png'.format(name))\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting data \n",
    "regressor.save(open('pickles/{}.p'.format(name), 'wb'))\n",
    "    \n",
    "dates = dates[shift:y_hat.shape[0]+shift]\n",
    "output_dict = {'Date':dates}\n",
    "for i, col in enumerate(target_cols):\n",
    "    output_dict[col] = y_hat[:,i]\n",
    "\n",
    "output_df = DataFrame(output_dict, columns=['Date']+target_cols)\n",
    "output_df.to_csv('./data/{}.csv'.format(name))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
